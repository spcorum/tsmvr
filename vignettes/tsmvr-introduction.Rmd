---
title: "An Introduction to Truly Sparse Multivariate Regression"
author: "Sean Corum"
date: "`r Sys.Date()`"
output: prettydoc::html_pretty
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Truly Sparse Multivariate Regression

__tsmvr__ or Truly Sparse Multivariate Regression is an R package for solving sparse multivariate regression problems with error coviance estimation. The workhourse algorithm in __tsmvr__ is adapted from the algorithm described by Chen and Gu in their paper "High Dimensional Multivariate Regression and Precision Matrix Estimation via Nonconvex Optimization" (ArXiv ID 1606.00832, 2016).

A multivariate regression problem is a regression problem with multiple responses. Formally,

$ \mathbf{Y} = \mathbf{X} \mathbf{B} + \mathbf{E} $

Here, \mathbf{X} is the design matrix of $n$ observations of $p$ features, \mathbf{Y} is the design matrix of $n$ observations of $q$ responses, \mathbf{B} is the regression matrix, and \mathbf{E} is the error term. Given  \mathbf{X} and \mathbf{Y}, __tsmvr__ solves this probem for \mathbf{B} under the constraint that \mathbf{B} is sparse and the condition that the errors may be correlated. Under the hood, the error correlations are encoded in the precision matrix \mathbf{\Omega}, which has its own sparsity constraint.

## A First Example

For a first example, define some problem parameters.

```{r first-parameters}
n = 1000                           # number of observations
p = 100                            # number of predictors
q = 10                             # number of responses
sparsity = 0.1                     # sparsity of true regression matrix
s1 = round(p * q * sparsity * 1.1) # fitted sparsity will be a little larger than the true sparsity
s2 = 3 * q - 4                     # constrains precision matrix to have the number of entries as a tri-diagonal matrix
```

The package __tsmvrextras__ contains functions for providing synthetic and real problems in a format ready to be input into __tsmvr__. The following code generates a synthetic dataset. Here, the dataset has a true regression matrix of `r sparsity`. See __tsmvrextras__ documentation for details about how the synthetic data are generated.

```{r first-data}
library(tsmvrextras)
set.seed(1729)
data = tsmvrextras::make_data(
  n = n, p = p, q = q, b1 = sqrt(sparsity), b2 = sqrt(sparsity)
)[[1]]
```

The function \code{tsmvr_solve} solves the regression problem using hard-thresholded block-wise alternating gradient descent.

```{r first-solution-gd-gd}
library(tsmvr)
solution = tsmvr::tsmvr_solve(
  X = data$X, Y = data$Y, s1 = s1, s2 = s2, 
  Omega_type = 'gd', eta1 = 0.05, eta2 = 0.2,
  skip = 50
)
```

For some problems like this one, an equally good solution instead may be found using alternating gradient descent-direct minimization.

```{r first-solution-gd-min, eval = F}
solution = tsmvr::tsmvr_solve(
  X = data$X, Y = data$Y, s1 = s1, s2 = s2, 
  Omega_type = 'min', eta1 = 0.002,
  skip = 50
)
```

## k-fold Cross Validation

k-fold cross validation may be performed using the function \code{tsmvr_cv}

```{r cross-validated}
set.seed(1)
validated = tsmvr::tsmvr_cv(
  X = data$X, Y = data$Y, s1 = s1, s2 = s2, k = 5,
  Omega_type = 'gd', eta1 = 0.05, eta2 = 0.2
)
```

## Replicated k-fold Cross Validation

Similarly, replicated k-fold cross validation may be performed using the function \code{tsmvr_replicate}

```{r replicated}
set.seed(3)
replicated = tsmvr::tsmvr_replicate(
  X = data$X, Y = data$Y, s1 = s1, s2 = s2, k = 5, reps = 3,
  Omega_type = 'gd', eta1 = 0.02, eta2 = 0.2
)
```

## Gridsearch


Also a quote using `>`:

> "He who gives up [code] safety for [code] speed deserves neither."
([via](https://twitter.com/hadleywickham/status/504368538874703872))
